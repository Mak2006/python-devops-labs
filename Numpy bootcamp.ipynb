{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy bootcamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy tips\n",
    "\n",
    "1. **What is it**\n",
    "    1. Array library, faster than built in python lists. Primarily because of Locality of reference, that is continuous memory locations. Written in Python, C and C++;\n",
    "    1. Why it is fast - two reasons, one is the data is held directly in memory. Losing a pointer helps faster lookups. Losing data size and precision speeds up computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Installation**\n",
    "\n",
    "`pip install numpy` and \n",
    "\n",
    "`import numpy as np`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Array creation  basics-** \n",
    "\t1.  arr = np.array(python list or tuple or any array);\n",
    "\t2.  indexing starts from 0. \n",
    "\t3.  arrays can be multi dimenstional viz \n",
    "\t4. `np.array([1,2,3,4])`\n",
    "\t5. `np.array([  [], []  ])`\n",
    "\t6. `np.array([   [ [],  []  ] ])`\n",
    "\t7.  \t8. access arr[a, b , c , d ]  - take the $a^{th}$ element within that take the $b^{th}$ element within that take the $c^{th}$ element and within that take the $d^{th}$. and so on. This would be possible from a 4D array.\n",
    "\t8. Negative indexing is there, 0 is the first element so -1 is the last element and so on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t1.  **Arange** - `n = np.arange(0, 20, 2)` creates a 1 D from 0 to 20 with step 2.  Note 20 is not included.\n",
    "\t2. **linspace** - `numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)` - creates an array from `start` to `stop` (included if `endpoint` =True, else not) containing `num` items in total.\n",
    "\t3. `n = ones((4, 3)) , zeros((4,3)), eye(4), diag(5), vstack([\ta, 2*a]), hstack([a, 2*a]) `\n",
    "\t4. We can write `np.zeros(2,3,4,5,6)` it will give us a appropriate n dim matrix.  In the above case `ndim` will be 5. How to visualize this ndim array? \tIt is hard to visualize, however, here is the way to represent it textually. An array containing 2 arrays each element of which is a 3 element array, each element of which is 4 element array and so on. \n",
    "\t5. arrange - `numpy.arange([start, ]stop, [step, ], dtype=None) -> numpy.ndarray` \n",
    "\t6.  \n",
    "\t7. How is arrange different from linspace. Linspace may or may not include the `end` while Arange never includes. Next Arange can take one argument `stop, start defaults to 0 and step defaults to 1` or two arguments `start and stop, step defaults to 1` \n",
    "\t8. `logspace` values are spaced logarithemically. \n",
    "\t9. `geomspace` values are spaced geometrically. \n",
    "\t10.  Random number generation -  **random** library - example  `p = np.random.randint(10, 100, 9)`\n",
    "\t11.  Create from a string using - `a = np.fromstring('20 30 40 90', dtype=np.int, sep=' ')` cre\n",
    "\t12. Another ways is to use the fill method - ``numpy.``full`(_shape_, _fill_value_, _dtype=None_, _order='C'_)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array attributes - `a.size, shape, ndim, itemsize, dtype, nbytes` ndim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Array slicing -** \n",
    "\t1. `newarr = oldarr[start : end : step]` THe defaults are 0 for start, arr.length() for end and 1 for step. Both the start index is included and **the end index is excluded**.  example `print(a[1:5:2])`\n",
    "\t2.  negative indexing exists. \n",
    "\t3.  Slicing 2d arrays - `newarr = old[arraySelection, itemSelection]` e.g. `newarr = arr[0:1, 2]` for all the elements 0 to 1, tget the $2^{th}$ element. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Reshape , Resize , Arange**\n",
    "\t6. Reshape  creates a new array. Resize changes to original. Linspace\n",
    "\t7. `np.reshape(array, commands)`\n",
    "\t8. `n = n.reshape(rows, cols)` \n",
    "\t9. `n = resize(row, cols)`\n",
    "\t10.**swap axes ** this si transpose. `a.swapaxes(0,1)` \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mathematical Operations \n",
    "\t1. `a.min(), a.max(), a.mean(), a.std()`\n",
    "\t2. `a.var() # variance`\n",
    "\t3. `print(g.argmin())      # index of min element`\n",
    "\t4. `print(g.argmax())      # index of max element`\n",
    "\t5. `print(g.argsort())     # returns array of indices that would put the array in sorted order`\n",
    "\t6. find where the min max occurs `a.argmax(), a.argmin()` \n",
    "\t7. `resize` and `reshape` helps in sizing. \n",
    "\t8. variables point to original array. `r.copy()` creates a new matrix. \n",
    "\t9. `r.reshape(4)` creates a 4x4 array. \n",
    "\t10. conditional assignment - `a[a>20] = 20` sets all items > 20 to 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Mathematical Operations \n",
    "\t1. `a.min(), a.max(), a.mean(), a.std()`\n",
    "\t2. `a.var() # variance`\n",
    "\t3. `print(g.argmin())      # index of min element`\n",
    "\t4. `print(g.argmax())      # index of max element`\n",
    "\t5. `print(g.argsort())     # returns array of indices that would put the array in sorted order`\n",
    "\t6. find where the min max occurs `a.argmax(), a.argmin()` \n",
    "\t7. `resize` and `reshape` helps in sizing. \n",
    "\t8. variables point to original array. `r.copy()` creates a new matrix. \n",
    "\t9. `r.reshape(4)` creates a 4x4 array. \n",
    "\t10. conditional assignment - `a[a>20] = 20` sets all items > 20 to 20. \n",
    "\t11.**Column operations** -   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. NaN -  this is not a number. \n",
    "\t1. Methods `np.isnan(var) = True` if it is a NaN\n",
    "\t2. `np.nan == None` returns false\n",
    "\t3. `np.nan == np.nan` returns false.\n",
    "\t4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Optimization - \n",
    "\t1. default data types are int32 and int64. these consume lots of memory. instead consider lower types if required `d = np.arange(0,100, dtype='int8')`\n",
    "11.  I/O\n",
    "\t1. `f = np.loadtxt('filedata.txt', skiprows=1, delimiter=',', dtype=np.int32)`\n",
    "\t2. saving `np.savetxt('data2.txt', f, delimiter=';', fmt='%d', header='a;b;c;d;e;f;g;h;i;j', comments='')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Distributions in numpy\n",
    "Distribution is the probability of the event happening vs the various events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-5636ffe7fe18>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-5636ffe7fe18>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Normal distributions\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Normal distributions \n",
    "sample = np.random.normal(loc=0.0, scale=1.0, size=sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial distributions \n",
    "\t2. `np.random.binomial(1, 0.5)`\n",
    "    2. n = number of trials, p = probability event of interest occurs on any one trial, size = number of times you want to run this experiment\n",
    "    3. [Numpy doc](https://numpy.org/doc/1.16/reference/generated/numpy.random.binomial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi square distribution \n",
    "    1. `chi_squared_df5 = np.random.chisquare(5, size=10000)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform distribution \n",
    "    1. `u = np.random.uniform(0, 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bimodal distributions \n",
    "    1. Gausian mixure models - two binomial distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. **Hypothesis testing** -\n",
    "    1. T tests, A/B testing\n",
    "    2. Be aware of P-hacking  where you get spurious correlation. This can be corrected by \n",
    "        1. Bonferroni correction - vary the alpha\n",
    "        2. Hold out sets - divide the data into sets, one for training and another for testing\n",
    "        3. Investigation pre-registration - connect to theory and prove the experiments are relevant. \n",
    "    3. Libraries - scipy\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
