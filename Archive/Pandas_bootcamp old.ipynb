{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "\n",
    "\n",
    "## Install and importing \n",
    "\n",
    "`pip install pandas` # for installation, assuming that this is already done\n",
    "\n",
    "`import pandas as pd; # in the code`\n",
    "\n",
    "further we get a data set to munch upon. There are two flavors of it \n",
    "1d data set =  and 2d data set. \n",
    "\n",
    "\n",
    "## Panda playgrounds where you can learn\n",
    "1. [Perfect you Pandas skills on Kaggle](https://www.kaggle.com/learn/pandas)\n",
    "1. [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/version/0.19/10min.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "1. Essentially 3 data structures, series, dataframe, panels\n",
    "\t1. Series is 1D, like a column, \n",
    "\t3. DataFrame is like 2D, worksheet\n",
    "\t4. Panel is 3d, like a excel file, multiple worksheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help when you are lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.         #press tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.add? #get help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "1. This is a list, it can either Stirings or numebrs  or both. It has index and a label. Index is integer sequence and starts with 0, while label is another set of strings making this a key value pair. \n",
    "3. Define - \n",
    "\t1. `animals = [\"tiger\", \"bear\", \"moose\"]` \n",
    "\t2. make it mixed `animals = [\"tiger\", \"bear\", 1, None]` \n",
    "\t3. Note for both cases when it is string and it is mixed, the underlying type is `dtype: object`\n",
    "\t4. Printing `pd.Series(animals)`or `s.head()`\n",
    "\t5.  Creating using labels `animals = [\"tiger\", \"bear\", \"moose\"]` \n",
    "\t6.  Defining a series with existing list or tuple or  dictionary. \n",
    "4. The definition of Series API is `pd.Series(data=None, index=None, dtype=None, name=None, copy=False, fastpath=False)[source]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "dtype: object\n",
      "0    b\n",
      "1    c\n",
      "2    d\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Flour     4 cups\n",
       "Milk       1 cup\n",
       "Eggs     2 large\n",
       "Spam       1 can\n",
       "Name: Dinner, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining using dic\n",
    "lidata = ['a', 'b', 'c']\n",
    "tudata = ('b', 'c', 'd')\n",
    "didata = {'Kite': 'paper',\n",
    "          'Chair': 'wood',\n",
    "          'Notebook': 'paper',\n",
    "          'Mirror': 'glass'}\n",
    "\n",
    "li = pd.Series(lidata) # all works\n",
    "print(li) #print it. \n",
    "tu = pd.Series(tudata)\n",
    "print(tu)\n",
    "\n",
    "#Invoking the api\n",
    "ingreds = pd.Series({'Flour': '4 cups', 'Milk':'1 cup', 'Eggs': '2 large', 'Spam': '1 can'}, name='Dinner')\n",
    "ingreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define using copy\n",
    "d1 = df1.copy()\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  7. - Continued \n",
    "     7. creating from random.  `s = pd.series(np.random.randint(0, 1000, 10000))`\n",
    "     9. \n",
    "   \t  \n",
    "\n",
    "4.  Defining index in series. \n",
    "\t1. Index is a list so would be defined by `[]` and can contain only strings. \n",
    "\t2. If List or tuple is being used index would have to contain exact number of arguments. \n",
    "\t3. If dict is being used index is already defined as the keys of ht edict and those are used. This is like a query and not a creation. \n",
    "5.  Query - either by index or index label.  There are two attributes to do this `iloc` and `loc` MNote these are not methods. They are attributes so usages are `s.iloc[3] or s.loc['Notebook']`\n",
    "\t 1. `s.iloc['2']` is error as we require int here as these are index. \n",
    "\t 2. `s.['3']` can work on dictionary having key `'3'` else it will throw error.\n",
    "\t 3. There is confusion if we are trying to index or we are referrind to keys, hence it isbetter to use loc and iloc. \n",
    "\t 4. \n",
    "6. Working witht he series\n",
    "\t1.  Do not iterate, use Vector methods\n",
    "\t2.  use numpy for the methods and pass them the series `import numpy as np`  `total = np.sum(s)` gives us summ of all numbers of s. Similarly `mean, min, max, std`\n",
    "\t3. `s+=2` increases all elements by 2, similary `-=, *= /=`\n",
    "\t4. `len(s)` gives the length of s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame\n",
    " \n",
    "### Creating data frames\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating directly using a DataFrame\n",
    "fruits = pd.DataFrame({'Apples': [30], 'Bananas': [21]})\n",
    "fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rob</th>\n",
       "      <th>Rick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Row name1</th>\n",
       "      <td>Very good.</td>\n",
       "      <td>Awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row name2</th>\n",
       "      <td>Not so good.</td>\n",
       "      <td>Boring.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Rob      Rick\n",
       "Row name1    Very good.  Awesome.\n",
       "Row name2  Not so good.   Boring."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More bigger dictionaries\n",
    "df1 = pd.DataFrame({'Rob': ['Very good.', 'Not so good.'], 'Rick': ['Awesome.', 'Boring.']}, index=['Row name1', 'Row name2'])\n",
    "\n",
    "# Note this index=['Product A', 'Product B'] is optional. \n",
    "## Nog\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dataFrame is created row in transposed way, that is we write all the columns first.\n",
    "\n",
    "The syntax is **pd.DataFrame(dict, indexList}** - example \n",
    "\n",
    "`df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],\n",
    "     index=['cobra', 'viper', 'sidewinder'],\n",
    "     columns=['max_speed', 'shield'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Good'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-26e721fad006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# how to remove an index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Good'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# add the old indexs as columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmain\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmain\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmain\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\bmain\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5017\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5019\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Good'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#Ah we set the index incorrectly \n",
    "df1.set_index([pd.Index(['Good', 'Bad'])]) # this denotes some of the columns as index\n",
    "\n",
    "# how to remove an index\n",
    "df1.drop(['Good']) \n",
    "\n",
    "# add the old indexs as columns\n",
    "df1.rest_index\n",
    "\n",
    "#add some existing index as columns\n",
    "df['index1'] = df.index   # this does not give intended results sometimes\n",
    "dfmax2015.reset_index(level=0, inplace=True) # better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the  columns names, this is handy sometimes\n",
    "df2 = pd.DataFrame({'Rob': ['Very good.', 'Not so good.'], 'Rick': ['Awesome.', 'Boring.']}, index=['Row name1', 'Row name2'])\n",
    "\n",
    "df2.rename(columns={'Rob':'Henry1',\n",
    "                          'Rick':'James1'}, inplace=True)\n",
    "df2\n",
    "\n",
    "#OTher ways\n",
    "e.columns = ['Country', 'Energy Supply', 'Energy Supply per Capita', '% Renewable']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a summary and views\n",
    "**we use head(), tail(), describe() and variables like dtypes, index, columns, values.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.describe() # gives a stat of the df1, very informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes # gives the types within the cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.values # gives the raw matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index # gives the index\n",
    "df1.index[0] # gives the first index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns # gives the names of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing and dicing, sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note some of slicing and dicing gets done on the original \n",
    "df1.Rob # Note here we use the col name as values. Rather than this method we shall use the [] method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Rob'] # this is same as df1.Rob, however,in this syntax we can use \" \", it is wordy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iloc** and **loc**, these are two important operators, not methods. iloc is index location while loc is just location.  These are used to locate a particular item. \n",
    "Note: both loc and iloc are row-first, column-second and this is opposite of python.\n",
    "\n",
    "Arguments of iloc \n",
    "iloc arguments have parts each of which can be the following\n",
    "```\n",
    "a single item - 0\n",
    "a range 0:1\n",
    "a list [0, 1, 3]\n",
    "all the range :\n",
    "```\n",
    "thus all of these as are possible. \n",
    "\n",
    "`iloc[:, [0,1,2]]`\n",
    "\n",
    "`iloc[0, :]`\n",
    "\n",
    "\n",
    "**Arguments of loc**\n",
    "loc arguments expects similar arguments as iloc. \n",
    "example - \n",
    "`df = df1.loc[[0,1,10,100], ['country', 'province', 'region_1', 'region_2']]` # give rows 0, 1, 10, 100 and the cols as cited. \n",
    "\n",
    "**Conditiional arguments** \n",
    "`df1.loc[df1.Rob == 'Some value']`\n",
    "\n",
    "`df1.loc[(df1.Rob == 'Some value') & (df1.SomeOtherCol == 'Some other val')]`\n",
    "\n",
    "` conditional operators == != | & are supported.`\n",
    "**Note it is not &&**\n",
    "\n",
    "** isin operator\n",
    "df1.loc[df1.Rob.isin(['val1', 'val2'])]  # get me thos records from df1 whose Rob colums have either val1 or val2.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1['Rob'].iloc[0]\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1.Rob.iloc[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1['Rob'][0] # df1.Rob gives a colums and hence adding a [] gives a item. \n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Row accessing** \n",
    "s = df1.iloc[0]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1.loc['Row name 1'] # gives an error, row names have to be exact.\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1.loc['Row name1']\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df1.loc[:, ['Rob']]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df1.Rob == 'Very good.'] # return the row where the col Rob equals those values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[2:4] # this returns nothing as there is no data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and SQL styles\n",
    "`sort_values() to sort by column(s)`\n",
    "\n",
    "`sort_index() to sort by the index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cols = ['Rob']\n",
    "df1.sort_values(list_of_cols, ascending=True) # Sorting based on columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting based on index\n",
    "df1.sort_index(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where clause \n",
    "df.where(df['SUMLEV']==50)\n",
    "    .dropna()\n",
    "    .set_index(['STNAME','CTYNAME'])\n",
    "    .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n",
    "    \n",
    "df = df[df['SUMLEV']==50]  # filter based on SUMLEV col keep only rows where it is 50\n",
    "\n",
    "#group by clause\n",
    "df.groupby('A').sum()\n",
    "\n",
    "#interesting application of groupby clause\n",
    "df = df.set_index('STNAME')\n",
    "\n",
    "def fun(item):\n",
    "    if item[0]<'M':\n",
    "        return 0\n",
    "    if item[0]<'Q':\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "for group, frame in df.groupby(fun):\n",
    "    print('There are ' + str(len(frame)) + ' records in group ' + str(group) + ' for processing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no data, so how do we add some data to existing stuff. \n",
    "### Adding values to dataframes \n",
    "Way 1 - use the array notation df['Col'] = 'val' # sets all the values to val\n",
    "Way 2 - populate with a range of values df.Col = range(0, len(df), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"New col\"] ={\"new value1\", \"new value 2\"} # adds a new col\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a new row\n",
    "#df1.append()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have more values, we look at the conditional operators\n",
    "\n",
    "### Conditional operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`df1.loc[df1.Rob == 'Some value']`\n",
    "'reviews.loc[reviews.price.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing  the values from a df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the column\n",
    "s = df1['Rob']\n",
    "s\n",
    "\n",
    "#Get the first item from the first col\n",
    "s = df1['Rob'][0]\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-eb4574a3ad3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# gets the row having the max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#Another function argmax gives us the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-eb4574a3ad3b>\u001b[0m in \u001b[0;36manswer_one\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Max min operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Gold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# gets the row having the max\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Max min operations \n",
    "def answer_one():\n",
    "    s = df.loc[df.Gold == df['Gold'].max()] # gets the row having the max\n",
    "    return s\n",
    "answer_one()\n",
    "\n",
    "#Another function argmax gives us the index \n",
    "result = Top15['% Renewable'].argmax()   #gives the row which is the max()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning values \n",
    "this is selection of the cells and transformation and application fo the values. \n",
    "`e['Energy Supply'].replace(['...'], [np.NaN], inplace=True)` # find the values ... and replace by NaN\n",
    "\n",
    "`w.female.replace(['male', 'female'], [1, 0], inplace=True)` # do the replace for multiple data with new data\n",
    "\n",
    "`e['Energy Supply'] = 1000000*e['Energy Supply']` # multiple a whole column\n",
    "\n",
    "`e['Country'] = e['Country'].str.replace(r\" \\(.*\\)\",\"\")` find patterna nd replace\n",
    "\n",
    "``` Replace using a dic\n",
    "\n",
    "    new_name={\"Republic of Korea\": \"South Korea\",\n",
    "                  \"United States of America\": \"United States\",\n",
    "                  \"United Kingdom of Great Britain and Northern Ireland\": \"United Kingdom\",\n",
    "                  \"China, Hong Kong Special Administrative Region\": \"Hong Kong\"}\n",
    "    e['Country'].replace(to_replace=new_name, inplace=True)\n",
    "```\n",
    "\n",
    "### Drop rows and colums\n",
    "`df.drop(['B', 'C'], axis=1)`  #droping by labels - axis = 0 means rows, 1 means cols\n",
    "\n",
    "`g = g.drop(g.columns[2:48], axis = 1)` # drop columns by index, drop the columns 2 to 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using maps, apply and lambdas\n",
    "use df.apply can be used.  [apply official](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html?highlight=apply#pandas.DataFrame.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sqrt) # do a square root of all elements of all columns, axis = 0 by default\n",
    "\n",
    "df.apply(np.sum, axis=0) # as a reducing function \n",
    "\n",
    "#In this call we are change the 'PR' column itself. \n",
    "sample['PR'] = sample['PR'].apply(lambda x: np.nan if x < 90 else x) # note the receiving array need not be the same\n",
    "\n",
    "#create a new colm spliting the value of exiting col\n",
    "dfmax['d'] = dfmax['Date'].apply(lambda x: (x[:4]))\n",
    "\n",
    "# Here is a one liner\n",
    "df['left'],df['right'] = zip(*df[0].apply(lambda x: x.split('|')))\n",
    "\n",
    "# Another example of the one line done in Ass 2 of Applied -- \n",
    "dfmin1['Year'], dfmin1['Month-date'] = zip(*dfmin['Date'].apply(lambda x: (x[:4], x[5:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced stat functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Top15' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1d77acb37703>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# correlation - dataframe.corr() givs pairwise correlation of columns - example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTop15\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cdpp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Energy Supply per Capita'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# example two row df containing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pearson'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# computes the correlation by pearson method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Top15' is not defined"
     ]
    }
   ],
   "source": [
    "# correlation - dataframe.corr() givs pairwise correlation of columns - example \n",
    "data = Top15[['cdpp','Energy Supply per Capita']] # example two row df containing data\n",
    "corr = data.corr(method='pearson').iloc[0,1] # computes the correlation by pearson method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the iloc and loc gotcha \n",
    "#df = reviews[['country', 'variety']].iloc[0:100] \n",
    "#df = reviews.loc[0:99, ['country', 'variety']]\n",
    "are the same however, one uses 0:99 and other uses 0:100 why "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type conversion\n",
    "How to get the data types and convert from one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes # get the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.astype(\"string\") # converts to object\n",
    "\n",
    "str(df1)  # prints a string of all the stuff \n",
    "\n",
    "k = str(df1.iloc[0, 0])\n",
    "\n",
    "type(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Series to list\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string in int\n",
    "df['DataFrame Column'] = df['DataFrame Column'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data frames \n",
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True)  #outer join \n",
    "\n",
    "how can be `outer` `inner`, `left`, `right` \n",
    "\n",
    "exisiting index of the df can be used - left_index and right_index equals tells that use the indexes of the df. A beeter way is to use left_on and right_on which requires the column names. This explicity tells the developer the join axis, hence better in that way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(staff_df, student_df, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the execution times\n",
    "%%timeit -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Output\n",
    "With Pandas it is possible to read from multiple sources, for example, CSV, HTML, JSON. \n",
    "\n",
    "[Official guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading from csv file\n",
    "reviews = pd.read_csv(\"../input/wine-reviews/winemag-data_first150k.csv\")\n",
    "## the file would have to be present in the directory. \n",
    "## The method is quite versatile and here are few important aspects\n",
    "# index_col=0 - set this if the file already has an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the df to a file\n",
    "df.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb8301764d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# reading from Excel file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# skip rows = header rows to skip. footer = footer rows to skip. use_cols = cols to take\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menergy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Energy Indicators.xls'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Energy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipfooter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# reading from Excel file. \n",
    "# skip rows = header rows to skip. footer = footer rows to skip. use_cols = cols to take\n",
    "energy = pd.read_excel('Energy Indicators.xls', sheet_name='Energy', skiprows =16, skipfooter=38, use_cols=\"C:F\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begining a project\n",
    "Here are few heuristics that saves lot of time\n",
    "\n",
    "1. Begin by taking in data being read from data file. \n",
    "2. Create a data frame\n",
    "1. Check the object type of the data, \n",
    "    1. df.dtypes # check the data type and the cols, as saves a call to df.columns\n",
    "    1. df.shape  # size of matrix\n",
    "    1. df.head() # actual data\n",
    "    1. df.describe() # if it has numeric values and we are directly going to use stats\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
